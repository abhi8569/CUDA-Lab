{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationAwareConv2d(torch.nn.Conv2d):\n",
    "    \n",
    "    def __init__(self,locationAware,gradient,w,h,in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
    "        \n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        \n",
    "        if locationAware:\n",
    "            self.locationBias=torch.nn.Parameter(torch.zeros(w,h,3))\n",
    "            self.locationEncode=torch.autograd.Variable(torch.ones(w,h,3))\n",
    "            \n",
    "            if gradient:\n",
    "                for i in range(w):\n",
    "                    self.locationEncode[i,:,1]=self.locationEncode[:,i,0]=i/float(w-1)\n",
    "        \n",
    "        self.up=torch.nn.Upsample(size=(w,h), mode='bilinear', align_corners=False)\n",
    "        self.w=w\n",
    "        self.h=h\n",
    "        self.locationAware=locationAware\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        if self.locationAware:\n",
    "            if self.locationBias.device != inputs.device:\n",
    "                self.locationBias=self.locationBias.to(inputs.get_device())\n",
    "                \n",
    "            if self.locationEncode.device != inputs.device:\n",
    "                self.locationEncode=self.locationEncode.to(inputs.get_device())\n",
    "                \n",
    "            b=self.locationBias*self.locationEncode\n",
    "            \n",
    "        convRes=super().forward(inputs)\n",
    "        \n",
    "        if convRes.shape[2]!=self.w and convRes.shape[3]!=self.h:\n",
    "            convRes=self.up(convRes)\n",
    "            \n",
    "        if self.locationAware:\n",
    "            return convRes+b[:,:,0]+b[:,:,1]+b[:,:,2]\n",
    "        \n",
    "        else:\n",
    "            return convRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NimbRoNet2 Model Class\n",
    "\"\"\"\n",
    "\n",
    "class NimbRoNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NimbRoNet2, self).__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        \"\"\"\n",
    "        Encoder Block\n",
    "        \"\"\"\n",
    "        self.e_block1 = nn.Sequential(*list(model.children())[0:5])\n",
    "        self.conv_1_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1)\n",
    "        \n",
    "        self.e_block2 = nn.Sequential(*list(model.children())[5:6])\n",
    "        self.conv_1_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1)\n",
    "        \n",
    "        self.e_block3 = nn.Sequential(*list(model.children())[6:7])\n",
    "        self.conv_1_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1)\n",
    "        \n",
    "        self.e_block4 = nn.Sequential(*list(model.children())[7:-2])\n",
    "        \"\"\"\n",
    "        Decoder Block\n",
    "        \"\"\"\n",
    "        self.d_block1 = nn.Sequential(\n",
    "                        nn.ReLU(),\n",
    "                        nn.ConvTranspose2d(in_channels = 512, out_channels=256, kernel_size=2, stride=2, padding=0, output_padding=0))\n",
    "        \n",
    "        self.d_block2 = nn.Sequential(\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(512),\n",
    "                        nn.ConvTranspose2d(in_channels = 512, out_channels=256, kernel_size=2, stride=2, padding=0, output_padding=0))\n",
    "        \n",
    "        self.d_block3 = nn.Sequential(\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(512),\n",
    "                        nn.ConvTranspose2d(in_channels = 512, out_channels=128, kernel_size=2, stride=2, padding=0, output_padding=0))\n",
    "        \n",
    "        self.d_block4 = nn.Sequential(\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.ConvTranspose2d(in_channels = 256,out_channels=3, kernel_size=1, stride=1, padding=0, output_padding=0))\n",
    "#                       LocationAwareConv2d())\n",
    "        \"\"\"\n",
    "        Location dependent convolution\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        encoder\n",
    "        \"\"\"\n",
    "        #print(\"Input : \",input.shape)\n",
    "        \n",
    "        output = self.e_block1(input)\n",
    "        #print(\"e_block1 : \",output.shape)\n",
    "        \n",
    "        res_1 = self.conv_1_1(output)\n",
    "        #print(\"res_1 : \",res_1.shape)\n",
    "        \n",
    "        output = self.e_block2(output)\n",
    "        #print(\"e_block2 : \",output.shape)\n",
    "        \n",
    "        res_2 = self.conv_1_2(output)\n",
    "        #print(\"res_2 : \",res_2.shape)\n",
    "        \n",
    "        output = self.e_block3(output)\n",
    "        #print(\"e_block3 : \",output.shape)\n",
    "        \n",
    "        res_3 = self.conv_1_3(output)\n",
    "        #print(\"res_3 : \",res_3.shape)\n",
    "        \n",
    "        output = self.e_block4(output)\n",
    "        #print(\"e_block4 : \",output.shape)\n",
    "        \"\"\"\n",
    "        decoder\n",
    "        \"\"\"\n",
    "        output = self.d_block1(output)\n",
    "        #print(\"d_block1 : \",output.shape)\n",
    "        \n",
    "        output = torch.cat((output, res_3), 1)\n",
    "        #print(\"d_block1 + res3 : \",output.shape)\n",
    "        \n",
    "        output = self.d_block2(output)\n",
    "        #print(\"d_block2 : \",output.shape)\n",
    "        \n",
    "        output = torch.cat((output, res_2), 1)\n",
    "        #print(\"d_block2 + res2 : \",output.shape)        \n",
    "        \n",
    "        output = self.d_block3(output)\n",
    "        #print(\"d_block3 : \",output.shape)\n",
    "        \n",
    "        output = torch.cat((output, res_1), 1)\n",
    "        print(\"d_block3 + res1 : \",output.shape)\n",
    "        \n",
    "        output = self.d_block4(output)\n",
    "        #print(\"d_block4 : \",output.shape)\n",
    "        \"\"\"\n",
    "        Location dependent convolution\n",
    "        \"\"\"\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
