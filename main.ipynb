{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from NimbRoNet2.ipynb\n",
      "importing Jupyter notebook from Utils.ipynb\n",
      "importing Jupyter notebook from Transformation.ipynb\n",
      "importing Jupyter notebook from CustomDataset.ipynb\n",
      "Device :  cuda\n",
      "Python Version :  3.7.5 (default, Oct 25 2019, 15:51:11) \n",
      "[GCC 7.3.0]\n",
      "Pytorch Version :  1.3.1\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb                #pip install import_ipynb\n",
    "from NimbRoNet2 import *\n",
    "from Utils import *\n",
    "from Transformation import *\n",
    "from CustomDataset import *\n",
    "import torch\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "    avDev = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "print(\"Device : \",avDev)\n",
    "print(\"Python Version : \",sys.version)\n",
    "print(\"Pytorch Version : \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob Train Dataset :  3598\n",
      "Segmentation Train Dataset :  1108\n"
     ]
    }
   ],
   "source": [
    "train_transforms = [Rescale((480,640)),\n",
    "              RandomVerticalFlip(),\n",
    "              RandomHorizontalFlip(),\n",
    "              ColorJitter(brightness=0.5, \n",
    "                          contrast=0.5, \n",
    "                          saturation=0.5,\n",
    "                          hue = 0.5),\n",
    "              ToTensor(), \n",
    "              Normalize([0.485, 0.456, 0.406], \n",
    "                        [0.229, 0.224, 0.225])]\n",
    "\n",
    "train_dataset = BlobTrainDataset(path = '../Project/data/blob/forceTrain',transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "#print_dataloader(train_loader, num_of_image= 3, avDev = avDev)\n",
    "\n",
    "print(\"Blob Train Dataset : \",len(train_dataset))\n",
    "\n",
    "seg_train_dataset = SegDataset(path = '../Project/data/segmentation/dataset', transform= None)\n",
    "seg_train_loader = torch.utils.data.DataLoader(dataset=seg_train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "print(\"Segmentation Train Dataset : \",len(seg_train_dataset))\n",
    "\n",
    "# k = 0\n",
    "# for i, test_data in enumerate(seg_train_loader):\n",
    "    \n",
    "#     for j in range(batch_size):\n",
    "#         print(test_data[0][j].size())\n",
    "#         plt.figure(figsize=(10,5))\n",
    "#         plt.subplot(1,2,1)\n",
    "#         plt.imshow(test_data[0][j].cpu())\n",
    "#         plt.subplot(1,2,2)\n",
    "        \n",
    "#         plt.imshow(test_data[1][j].cpu())\n",
    "#         plt.show()\n",
    "#     k = k + 1\n",
    "#     if k == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NimbRoNet2()\n",
    "model.to(avDev)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion.to(avDev)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "                        {\"params\":model.e_block1.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.e_block2.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.e_block3.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.e_block4.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.d_block1.parameters()},\n",
    "                        {\"params\":model.d_block2.parameters()},\n",
    "                        {\"params\":model.d_block3.parameters()},\n",
    "                        {\"params\":model.d_block4.parameters()},\n",
    "                        {\"params\":model.conv_1_1.parameters()},\n",
    "                        {\"params\":model.conv_1_2.parameters()},\n",
    "                        {\"params\":model.conv_1_3.parameters()}], lr=0.001)\n",
    "\n",
    "# checkpoint = torch.load(\"model.pth\")\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# no_epoch = checkpoint['epoch']\n",
    "# print(\"No of epoch : \",no_epoch)\n",
    "# train_loss_1 = checkpoint['train_loss1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "torch.Size([5, 3, 120, 160])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abishek/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([5, 480, 640])) that is different to the input size (torch.Size([5, 3, 120, 160])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (160) must match the size of tensor b (640) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b86219462688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavDev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Session 9/code/Utils.ipynb\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, mode, train_loader, criterion, optimizer, device)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (160) must match the size of tensor b (640) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "total_loss = 0.0\n",
    "loss_details = [None]*100\n",
    "for epoch in range(2):\n",
    "\n",
    "    print(\"epoch\",epoch)\n",
    "    train_loss_, model = train_model(model, \"seg\", seg_train_loader, criterion, optimizer, avDev)\n",
    "    loss_details[epoch] = train_loss_\n",
    "    print(\"train loss\",train_loss_)\n",
    "    total_loss += train_loss_\n",
    "    print(\"total loss\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'train_loss1': loss_details,\n",
    "#             }, \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = [Rescale((480,640)),\n",
    "              ToTensor(), \n",
    "              Normalize([0.485, 0.456, 0.406], \n",
    "                        [0.229, 0.224, 0.225])]\n",
    "\n",
    "test_dataset = BlobTestDataset(path = '../Project/data/blob/forceTest',transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "recall = torch.zeros(3)\n",
    "tp = torch.zeros(3)\n",
    "fp = torch.zeros(3)\n",
    "fn = torch.zeros(3)\n",
    "fdr = torch.zeros(3)\n",
    "acc = torch.zeros(len(test_loader))\n",
    "\n",
    "for i, test_data in enumerate(test_loader):\n",
    "    \n",
    "    images = test_data[\"image\"].to(avDev)\n",
    "    ball = test_data[\"ball_detail\"].to(avDev)\n",
    "    goalpost = test_data[\"goalpost_detail\"].to(avDev)\n",
    "    robot = test_data[\"robot_detail\"].to(avDev)\n",
    "    \n",
    "    images.requires_grad_(False)\n",
    "    ball.requires_grad_(False)\n",
    "    goalpost.requires_grad_(False)\n",
    "    robot.requires_grad_(False)\n",
    "    \n",
    "    output = model(images)\n",
    "    \n",
    "    batch_len = output.shape[0]\n",
    "    \n",
    "    for j in range(batch_len):\n",
    "        \n",
    "        ball_center = center_of_shape(output[j][0].cpu().detach().numpy())\n",
    "        b_tp, b_fn, b_fp = metric_calculation(ball[j], ball_center, 4)\n",
    "        tp[0] += b_tp\n",
    "        fp[0] += b_fp\n",
    "        fn[0] += b_fn\n",
    "        \n",
    "        goalpost_center = center_of_shape(output[j][1].cpu().detach().numpy())\n",
    "        g_tp, g_fn, g_fp = metric_calculation(goalpost[j], goalpost_center, 4)\n",
    "        tp[1] += g_tp\n",
    "        fp[1] += g_fp\n",
    "        fn[1] += g_fn\n",
    "        \n",
    "        robot_center = center_of_shape(output[j][2].cpu().detach().numpy())\n",
    "        r_tp, r_fn, r_fp = metric_calculation(robot[j], robot_center, 4)\n",
    "        tp[2] += r_tp\n",
    "        fp[2] += r_fp\n",
    "        fn[2] += r_fn\n",
    "        \n",
    "    acc[i] = torch.mean(tp) / (torch.mean(tp) + torch.mean(fn) + torch.mean(fp))\n",
    "\n",
    "for i in range(3):\n",
    "    recall[i] = (tp[i])/(tp[i]+fn[i])\n",
    "    fdr[i] = (fp[i])/(fp[i]+tp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall of Ball \"+str(round(float(recall[0]),2)) )\n",
    "print(\"Recall of Goalpost \"+str(round(float(recall[1] ),2)))\n",
    "print(\"Recall of Robot \"+str(round(float(recall[2]),2)) )\n",
    "\n",
    "print(\"FDR of Ball \"+str(round(float(fdr[0] ),2)))\n",
    "print(\"FDR of Goalpost \"+str(round(float(fdr[1]),2)))\n",
    "print(\"FDR of Robot \"+str(round(float(fdr[2]),2)))\n",
    "\n",
    "total_recall = torch.mean(recall)\n",
    "total_fdr = torch.mean(fdr)\n",
    "\n",
    "print(\"Total recall \"  +str(round(float(total_recall),2)))\n",
    "print(\"Total FDR \"  +str(round(float(total_fdr),2)))\n",
    "print(\"Accuracy \" +str(round(float(acc.mean()),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "for j,test_data in enumerate(test_loader):\n",
    "      \n",
    "    images = test_data[\"image\"].to(avDev)\n",
    "    ball = test_data[\"ball_detail\"].to(avDev)\n",
    "    goalpost = test_data[\"goalpost_detail\"].to(avDev)\n",
    "    robot = test_data[\"robot_detail\"].to(avDev)\n",
    "    \n",
    "    images.requires_grad_(False)\n",
    "    ball.requires_grad_(False)\n",
    "    goalpost.requires_grad_(False)\n",
    "    robot.requires_grad_(False)\n",
    "\n",
    "    batch = test_data['image'].shape[0]\n",
    "    \n",
    "    for i in range(batch):\n",
    "        k += 1\n",
    "        plt.figure(figsize=(40,20))\n",
    "        plt.subplot(2,3,1)\n",
    "        plt.title('Test image' + str(k))\n",
    "        plt.imshow(images[i][0].cpu())\n",
    "        out = model(images)\n",
    "        plt.subplot(2,3,2)\n",
    "        plt.title('Ball')\n",
    "        plt.imshow(out[i][0].cpu().detach().numpy(), cmap= 'gray')\n",
    "        plt.subplot(2,3,3)\n",
    "        plt.title('Goalpost')\n",
    "        plt.imshow(out[i][1].cpu().detach().numpy(), cmap= 'gray')\n",
    "        plt.subplot(2,3,5)\n",
    "        plt.title('Robot')\n",
    "        plt.imshow(out[i][2].cpu().detach().numpy(), cmap= 'gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
