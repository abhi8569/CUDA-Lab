{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb                #pip install import_ipynb\n",
    "from NimbRoNet2 import *\n",
    "from Utils import *\n",
    "from Transformation import *\n",
    "from CustomDataset import *\n",
    "import torch\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    avDev = torch.device(\"cuda\")\n",
    "else:\n",
    "    avDev = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "print(\"Device : \",avDev)\n",
    "print(\"Python Version : \",sys.version)\n",
    "print(\"Pytorch Version : \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = [Rescale((480,640)),\n",
    "              RandomVerticalFlip(),\n",
    "              RandomHorizontalFlip(),\n",
    "              ColorJitter(brightness=0.5, \n",
    "                          contrast=0.5, \n",
    "                          saturation=0.5,\n",
    "                          hue = 0.5),\n",
    "              ToTensor(),\n",
    "              Normalize([0.485, 0.456, 0.406], \n",
    "                        [0.229, 0.224, 0.225])]\n",
    "\n",
    "train_dataset = BlobTrainDataset(path = '../Project/data/blob/forceTrain',transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# print_dataloader(train_loader, num_of_image= 3, avDev = avDev)\n",
    "\n",
    "print(\"Blob Train Dataset : \",len(train_dataset))\n",
    "\n",
    "seg_train_dataset = SegDataset(path = '../Project/data/segmentation/dataset', transform= None)\n",
    "seg_train_loader = torch.utils.data.DataLoader(dataset=seg_train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "print(\"Segmentation Train Dataset : \",len(seg_train_dataset))\n",
    "\n",
    "for i, test_data in enumerate(seg_train_loader):\n",
    "\n",
    "    plt.figure(figsize=(50,25))\n",
    "    print(test_data[0].size())\n",
    "    plt.imshow(torchvision.utils.make_grid(test_data[0], nrow=5).permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(50,25))\n",
    "#     plt.imshow(torchvision.utils.make_grid(test_data[1], nrow=1).permute(1, 2, 0))\n",
    "#     plt.imshow(torchvision.utils.make_grid(test_data[1][0], nrow=5).permute(1, 2, 0))\n",
    "    plt.imshow(test_data[1][0].cpu().detach().numpy(), interpolation='nearest')\n",
    "    print(test_data[1][0].cpu().detach().numpy().size)\n",
    "    plt.show()\n",
    "#     print(np.array(test_data[1][0]))\n",
    "    raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NimbRoNet2()\n",
    "model.to(avDev)\n",
    "\n",
    "criterion_blob = nn.MSELoss()\n",
    "criterion_seg = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion_blob.to(avDev)\n",
    "criterion_seg.to(avDev)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "                        {\"params\":model.e_block1.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.e_block2.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.e_block3.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.e_block4.parameters(), \"lr\": 0.000001},\n",
    "                        {\"params\":model.d_block1.parameters()},\n",
    "                        {\"params\":model.d_block2.parameters()},\n",
    "                        {\"params\":model.d_block3.parameters()},\n",
    "                        {\"params\":model.d_block4.parameters()},\n",
    "                        {\"params\":model.conv_1_1.parameters()},\n",
    "                        {\"params\":model.conv_1_2.parameters()},\n",
    "                        {\"params\":model.conv_1_3.parameters()}], lr=0.001)\n",
    "\n",
    "checkpoint = torch.load(\"../model.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "no_epoch = checkpoint['epoch']\n",
    "print(\"No of epoch : \",no_epoch)\n",
    "train_loss_1 = checkpoint['train_loss1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0.0\n",
    "loss_details = [None]*100\n",
    "train_loss = 0.0\n",
    "\n",
    "combined_loader = [train_loader, seg_train_loader]\n",
    "\n",
    "for epoch in range(no_epoch, no_epoch + 2):\n",
    "\n",
    "    print(\"epoch\",epoch)\n",
    "    train_loss, model = train_model(model, \"seg\", combined_loader, criterion_blob, criterion_seg, optimizer, avDev)\n",
    "    loss_details[epoch] = train_loss\n",
    "    print(\"train loss\",train_loss)\n",
    "    total_loss += train_loss\n",
    "    #print(\"total loss\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss1': loss_details,\n",
    "            }, \"../model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = [Rescale((480,640)),\n",
    "              ToTensor(), \n",
    "              Normalize([0.485, 0.456, 0.406], \n",
    "                        [0.229, 0.224, 0.225])]\n",
    "\n",
    "test_dataset = BlobTestDataset(path = '../Project/data/blob/forceTest',transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=True)\n",
    "\n",
    "seg_test_dataset = SegDataset(path = '../Project/data/segmentation/forceTrain',transform=None)\n",
    "seg_test_loader = torch.utils.data.DataLoader(dataset=seg_test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# blob_test(model, test_loader, avDev)\n",
    "# blob_test_output(model, test_loader, avDev)\n",
    "\n",
    "total_test = 0\n",
    "correct_test = 0\n",
    "\n",
    "for i, test_data in enumerate(seg_test_loader):\n",
    "    if(i <= 0):\n",
    "        images = test_data[0].to(avDev)\n",
    "        target = test_data[1].to(avDev)\n",
    "\n",
    "        output = model(images)\n",
    "        \n",
    "        _,predicted = torch.max(output.data, 1)\n",
    "        total_test += target.nelement()\n",
    "        correct_test += predicted.eq(target.data).sum().item()\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        print(\"Accuracy : \", test_accuracy)\n",
    "        \n",
    "        for i in range(output.shape[0]):\n",
    "        \n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title('Test image')\n",
    "            #print(images[i].size())\n",
    "            plt.imshow(np.transpose(images[i].cpu().detach().numpy(), (1, 2, 0)))\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title('Segmentaed Image')\n",
    "            plt.imshow(np.transpose(output[i].cpu().detach().numpy(), (1, 2, 0)).mean(axis = 2), cmap = 'gray')\n",
    "            #channel 0 background; 1 line; 2 ground\n",
    "    #         plt.imshow(torchvision.utils.make_grid(output.cpu().detach()[0][2,:,:], nrow=5).permute(1, 2, 0))\n",
    "            #plt.imshow(torchvision.utils.make_grid([1, 1, 1] - output.cpu().detach().numpy(), nrow=5).permute(1, 2, 0))\n",
    "            plt.show()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,test_data in enumerate(seg_test_loader):\n",
    "      \n",
    "    images = test_data[0].to(avDev)\n",
    "    label = test_data[1].to(avDev)\n",
    "    \n",
    "    images.requires_grad_(False)\n",
    "    label.requires_grad_(False)\n",
    "    \n",
    "    batch = test_data['image'].shape[0]\n",
    "    \n",
    "    for i in range(5):\n",
    "        k += 1\n",
    "        plt.figure(figsize=(40,20))\n",
    "        plt.subplot(2,3,1)\n",
    "        plt.title('Test image' + str(k))\n",
    "        plt.imshow(images[0][i].cpu())\n",
    "        out = model(images)\n",
    "        plt.subplot(2,3,2)\n",
    "        plt.title('Ball')\n",
    "        plt.imshow(out[i][0].cpu().detach().numpy(), cmap= 'gray')\n",
    "        plt.subplot(2,3,3)\n",
    "        plt.title('Goalpost')\n",
    "        plt.imshow(out[i][1].cpu().detach().numpy(), cmap= 'gray')\n",
    "        plt.subplot(2,3,5)\n",
    "        plt.title('Robot')\n",
    "        plt.imshow(out[i][2].cpu().detach().numpy(), cmap= 'gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
